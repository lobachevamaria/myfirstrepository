# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1

### –ó–∞–¥–∞–Ω–∏–µ 1
```python
ime=input('–ò–º—è: ')
vozrast=int(input('–í–æ–∑—Ä–∞—Å—Ç: '))
print(f'–ü—Ä–∏–≤–µ—Ç, {ime}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {vozrast+1}.')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab01/1.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```python
a=(input('–ß–∏—Å–ª–æ a: ')).replace(',','.')
b=(input('–ß–∏—Å–ª–æ b: ')).replace(',','.')
sum=round((float(a)+float(b)),2)
avg=round((float(a)+float(b))/2,2)
print(f'–°—É–º–º–∞ = {sum} ; –°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ = {avg}')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab01/2.png)


### –ó–∞–¥–∞–Ω–∏–µ 3
```python
price = float(input('–í–≤–µ–¥–∏—Ç–µ —Ü–µ–Ω—É: '))
disc = float(input('–í–≤–µ–¥–∏—Ç–µ —Å–∫–∏–¥–∫—É: '))
vat = float(input('–í–≤–µ–¥–∏—Ç–µ –ù–î–°: '))
base = price * (1 - disc / 100)
vat_amount =base * (vat / 100)
total = base + vat_amount
print(f'–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏:{base:.2f} –†')
print(f'–ù–î–°:{vat_amount:.2f} –†')
print(f'–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:{total:.2f} –†')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](images/lab01/3.png)

### –ó–∞–¥–∞–Ω–∏–µ 4
```python
vrema=int(input('–í–≤–µ–¥–∏—Ç–µ –∫–æ–ª-–≤–æ –º–∏–Ω—É—Ç '))
chas=vrema//60
print(f' –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥–∞: {chas}:{vrema-(chas*60)}')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](images/lab01/4.png)

### –ó–∞–¥–∞–Ω–∏–µ 5
```python
fio=input('–§–ò–û: ')
inic=''
dl=0
x=fio.split()
for i in range(0,len(x)):
    inic=inic+x[i][0]+'.'
    dl=len(x[i])+dl
print(f'–ò–Ω–∏—Ü–∏–∞–ª—ã: {inic[:-1]}')
print(f'–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {dl+2}')
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](images/lab01/5.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2
### –ó–∞–¥–∞–Ω–∏–µ 1.1
```python
def min_max(nums:list[float|int])->tuple[float|int, float| int]:
    if len(nums)==0:
         return ValueError
    mi=100000000000000000
    ma=-100000000000000000
    for i in range(0,len(nums)):
        if nums[i]<mi:
            mi=nums[i]
        if nums[i]>ma:
            ma=nums[i]
    return tuple([mi, ma])
print(min_max([1.5, 2, 2.0, -3.1]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab02/1.1.png)

### –ó–∞–¥–∞–Ω–∏–µ 1.2
```python
def unique_sorted(nums:list[float|int])->list[float|int]:
    return sorted(set(nums))
print(unique_sorted([3,1,2,1,3]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab02/1.2.png)

### –ó–∞–¥–∞–Ω–∏–µ 1.3
```python
def flatten(mat:list[list| tuple])->list:
    array=list()
    for arr in mat:
        if not(isinstance(arr,tuple) or isinstance(arr,list)):
            return TypeError
        for member in arr:
            array.append(member)
    return array
print(flatten([[1,2],[3,4]]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](images/lab02/1.3.png)

### –ó–∞–¥–∞–Ω–∏–µ B.1
```python
def transpose(mat:list[list[float|int]])->list[list]:
    if len(mat)==0:
        return []
    if any(len(mat[0])!=len(mat[i]) for i in range(len(mat))):
        return ValueError
    new=[[0 for j in range(len(mat))] for i in range(len(mat[0]))]
    for i in range(len(mat)):
        for j in range(len(mat[i])):
            new[j][i]=mat[i][j]
    return new
print(transpose([[1,2],[3,4]]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](images/lab02/B.1.png)

### –ó–∞–¥–∞–Ω–∏–µ B.2
```python
def row_sums(mat:list[list[float|int]])->list[float]:
    if any(len(mat[0]) != len(mat[i]) for i in range(len(mat))):
        return ValueError
    array=list()
    for arr in mat:
        array.append(sum(arr))
    return array
print(row_sums([[1,2,3], [4,5,6]]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](images/lab02/B.2.png)

### –ó–∞–¥–∞–Ω–∏–µ B.3
```python
def col_sums(mat:list[list[float|int]])->list[float]:
    if any (len(mat[0])!=len(mat[i]) for i in range (len(mat))):
        return ValueError
    array=list(0 for i in range(len(mat[0])))
    for i in range(len(mat)):
        for j in range(len(mat[i])):
            array[j]+=mat[i][j]
    return array
print(col_sums([[1,2,3],[4,5,6]]))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](images/lab02/B.3.png)

### –ó–∞–¥–∞–Ω–∏–µ C
```python
def format_record(rec:tuple[str,str,float]):
    name_data=rec[0].strip().split()
    if len(name_data)>2:
        surname,name,otchestvo=rec[0].strip().split()
        new_name_data=f'{surname[0].upper()}{surname[1:]} {name[0].upper()} {otchestvo[0].upper()}'
    elif len(name_data)==2:
        surname, name = rec[0].strip().split()
        new_name_data = f'{surname[0].upper()}{surname[1:]} {name[0].upper()} '
    elif len(name_data)==1:
        surname,  = rec[0].strip().split()
        new_name_data = f'{surname[0].upper()}{surname[1:]} '
    else:
        return ValueError
    group=rec[1].strip()
    if group=='':
        return ValueError
    try:
        gpa=float(rec[2])
    except Exception as _:
        return TypeError
    return f'{new_name_data}, –≥—Ä. {group}, GPA {gpa:.2f}'
print(format_record(("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0)))

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 7](images/lab02/C.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3

### –ó–∞–¥–∞–Ω–∏–µ –ê
```python
import re

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace('–Å', '–ï').replace('—ë', '–µ')
    text = ' '.join(text.strip().split())
    return text
print(normalize("Hello\r\nWorld"))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞"))
print(normalize("Hello\r\nWorld"))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))

def tokenize(text: str) -> list[str]:
    pattern = r'\w+(?:-\w+)*'
    tokens = re.findall(pattern, text)
    return tokens
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))
def count_freq(tokens: list[str]) -> dict[str, int]:
    freq = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1
    return freq

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    sorted_items = sorted(
        freq.items(),
        key=lambda x: (-x[1], x[0])
    )
    return sorted_items[:n]
print(top_n(count_freq(["a","b","a","c","b","a"]),n=2))
print(top_n(count_freq(["bb","aa","bb","aa","cc"]),n=2))
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab03/a.png)

### –ó–∞–¥–∞–Ω–∏–µ –í
```
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lib.text import normalize, tokenize, count_freq, top_n

# –ß—Ç–µ–Ω–∏–µ –≤—Å–µ–≥–æ –≤–≤–æ–¥–∞ –∏–∑ stdin
text = sys.stdin.readline()

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
normalized_text = normalize(text)

# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
tokens = tokenize(normalized_text)

# –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
total_words = len(tokens)
freq_dict = count_freq(tokens)
unique_words = len(freq_dict)
top_words = top_n(freq_dict, 5)

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
print("–¢–æ–ø-5:")

for word, count in top_words:
    print(f"{word}:{count}")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab03/b.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4

### io_txt_csv
```python
import csv
from pathlib import Path
from typing import Iterable, Sequence
from collections import Counter
import sys
import os

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lib.text import normalize, tokenize, count_freq, top_n

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """–§—É–Ω–∫—Ü–∏—è —Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É"""
    p = Path(path)
    # FileNotFoundError –∏ UnicodeDecodeError –ø—É—Å—Ç—å ¬´–≤—Å–ø–ª—ã–≤–∞—é—Ç¬ª ‚Äî —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
    return p.read_text(encoding=encoding)

def write_csv(rows: Iterable[Sequence], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    """–§—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–µ—Ç cvs —Ñ–∞–π–ª"""
    p = Path(path)
    rows = list(rows)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)

def frequencies_from_text(text: str) -> dict[str, int]:
    """–§—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—à–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å: —Å–ª–æ–≤–æ - —á–∞—Å—Ç–æ—Ç–∞ """
    tokens = tokenize(normalize(text))
    return Counter(tokens)  # dict-like

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã"""
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
```
### text_report
```python
import sys
import os
from pathlib import Path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lab04.io_txt_csv import read_text, write_csv,sorted_word_counts,frequencies_from_text
from lib.text import summary

def main():
    try:
      content = read_text("./data/input.txt")
      if not content.strip():
          print("–§–∞–π–ª –ø—É—Å—Ç")
          write_csv([], "./data/report.csv", header=("word", "count"))
      else:
          print (summary(content))
          content = write_csv(sorted_word_counts(frequencies_from_text(content)),"./data/report.csv", header=("word", "freq") )
      print ()
    except FileNotFoundError as e:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {e}")
    except UnicodeDecodeError:
        print("–û—à–∏–±–∫–∞: –ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π —Ñ–∞–π–ª–∞!")
    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab04/1.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5

### csv_json
```python
import json
import csv
from pathlib import Path


def csv_to_json(csv_path: str, json_path: str) -> None:
    file_csv=Path(csv_path)

    if not file_csv.exists():
        return FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if file_csv.suffix != ".csv":
        return ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö")

    with open(file_csv, "r", encoding='utf-8') as f:
        reader=csv.DictReader(f)

        if reader.fieldnames is None:
            return ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ —Ñ–∞–π–ª–µ")
        dano=list(reader)
    if len(dano)==0:
        return ValueError("–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª")

    with open(json_path, "w", encoding='utf-8') as f:
        json.dump(dano, f, ensure_ascii=False, indent=2)
csv_to_json("data/samples/test.csv","data/out/test_from_csv.json.json")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab05/test_from_csv_to_json.png)
### json_csv
```python
import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    file_json=Path(json_path)

    if not file_json.exists():
        return FileNotFoundError("—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    try:
        with file_json.open('r',encoding='utf-8') as f:
            dano=json.load(f)
    except json.JSONDecodeError:
        return ValueError("–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")

    except not isinstance(dano,list):
        return ValueError("JSON –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±—ã—Ç—å –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤")

    except len(dano)==0:
        return ValueError("JSON —Ñ–∞–π–ª –ø—É—Å—Ç")

    except not all(isinstance(item, dict) for item in dano):
        return ValueError("–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")

    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=tuple(dano[0].keys()))
            writer.writeheader()
            writer.writerows(dano)
json_to_csv("data/samples/test.json","data/out/test_from_json.csv")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab05/test_from_json_to_csv.png)
### csv_xlsx
```python
import csv
from pathlib import Path
from openpyxl import Workbook
from openpyxl.utils import get_column_letter

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    csv_file=Path(csv_path)
    if not csv_file.exists():
        return FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    if csv_file.suffix != '.csv':
        return ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
    wb=Workbook()
    ws=wb.active
    ws.title="Sheet1"

    with open(csv_path, 'r', encoding='utf-8') as f:
        reader= csv.DictReader(f)
        rows = list(reader)
    if len(rows)==0:
        return ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")
    if not reader.fieldnames:
        return ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞")

    ws.append(reader.fieldnames)

    r_count=0
    for row in rows:
        r_count+=1

        data_for_ex=[]
        for title in reader.fieldnames:
            data_for_ex.append(row[title])
        ws.append(data_for_ex)
    if r_count == 0:
        return ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")


    for col_index in range(1,len(reader.fieldnames)+1):
        column_letter=get_column_letter(col_index)
        max_len=0
        for row in ws[column_letter]:
            if row.value is not None:
                max_len=max(max_len,len(str(row.value)))

        m_width=max(max_len+2, 8)
        ws.column_dimensions[column_letter].width =m_width
    xlsx_path = Path(xlsx_path)
    wb.save(xlsx_path)

csv_to_xlsx("data/samples/people.csv","data/out/people.xlsx")
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](images/lab05/xlsx.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6

### cli_text
```python
import argparse
from pathlib import Path
from src.lib.text import tokenize, count_freq, top_n

def main():
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    subparsers=parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ–º–∞–Ω–¥—ã")

    stats_parser = subparsers.add_parser("stats",help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ")
    stats_parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    stats_parser.add_argument("--top", type=int,default=5,help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–æ–≤—ã—Ö —Å–ª–æ–≤ "
    "(–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)")

    cat_parser=subparsers.add_parser("cat", help="–í—ã–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n",action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    args = parser.parse_args()

    file=Path(args.input)

    if not file.exists():
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")


    if args.command == "cat":

        with open(file, "r", encoding="utf-8") as f:
            number=1
            for row in f:
                row = row.rstrip("\n")
                if args.n:
                    print(f"{number} : {row}")
                    number+=1
                else:
                    print(row)

    elif args.command == "stats":

        with open(file, "r", encoding="utf-8") as f:
            data=[row for row in f]
        data = "".join(data)
        tokens = tokenize(text=data)
        freq = count_freq(tokens=tokens)
        top=top_n(freq=freq, n = args.top)

        number=1
        for x, y in top:
            print(f"{number}. {x} - {y}")
            number+=1
if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab06/cat.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab06/stats5.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](images/lab06/stats3.png)
### cli_convert
```python
import argparse
from src.lib.json_csv import json_to_csv, csv_to_json
from src.lib.csv_xlsx import csv_to_xlsx

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏")
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")

    json_to_csv_parser = subparsers.add_parser("json_to_csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV")
    json_to_csv_parser.add_argument("--in", dest = "input", required= True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    json_to_csv_parser.add_argument("--out", dest = "output", required = True, help="–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")


    csv_to_json_parser = subparsers.add_parser("csv_to_json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON")
    csv_to_json_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_json_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")

    csv_to_xlsx_parser = subparsers.add_parser("csv_to_xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ XLSX")
    csv_to_xlsx_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_xlsx_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π XLSX —Ñ–∞–π–ª")

    args = parser.parse_args()

    if args.command == "json_to_csv":
        json_to_csv(json_path=args.input, csv_path=args.output)

    elif  args.command == "csv_to_json":
        csv_to_json(csv_path=args.input, json_path=args.output)

    elif args.command == "csv_to_xlsx":
        csv_to_xlsx(csv_path=args.input, xlsx_path=args.output)

if __name__ == "__main__":
    main()
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 4](images/lab06/c_to_j.png)

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 5](images/lab06/j_to_c.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 6](images/lab06/c_to_x.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7

### test_text.py
```python
import pytest

from src.lib.text import count_freq, normalize, tokenize, top_n


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize(src, expected):
    assert normalize(src) == expected


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize(src, expected):
    assert tokenize(src) == expected


def test_count_and_top():
    tokens = ["a", "b", "a", "c", "b", "a"]
    freq = count_freq(tokens)
    assert freq == {"a": 3, "b": 2, "c": 1}
    assert top_n(freq, 2) == [("a", 3), ("b", 2)]


def test_top_tie_breaker():
    freq = count_freq(["bb", "aa", "bb", "aa", "cc"])
    assert top_n(freq, 2) == [("aa", 2), ("bb", 2)]


def test_dop():
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—É—Å—Ç—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    assert normalize("") == ""
    assert tokenize("") == []
    assert count_freq([]) == {}
    assert top_n({}, 5) == []


def test_top_dop():
    """–ó–∞–ø—Ä–æ—Å –±–æ–ª—å—à–µ–≥–æ N —á–µ–º –µ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    freq = {"a": 3, "b": 2}
    assert top_n(freq, 5) == [("a", 3), ("b", 2)]
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab07/test_text.png)

### test_json_csv.py
```python
import json, csv
from pathlib import Path
import pytest
from src.lab05.json_csv import json_to_csv
from src.lab05.csv_json import csv_to_json


def write_json(path: Path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

def read_csv_rows(path: Path):
    with path.open(encoding="utf-8") as f:
        return list(csv.DictReader(f))

def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}]
    write_json(src, data)

    json_to_csv(str(src), str(dst))
    rows = read_csv_rows(dst)
    assert len(rows) == 2
    assert set(rows[0]) >= {"name", "age"}

def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    src.write_text("name,age\nAlice,22\nBob,25\n", encoding="utf-8")

    csv_to_json(str(src), str(dst))
    obj = json.loads(dst.read_text(encoding="utf-8"))
    assert isinstance(obj, list) and len(obj) == 2
    assert set(obj[0]) == {"name", "age"}

def test_json_to_csv_empty(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –ø—É—Å—Ç–æ–≥–æ JSON - –æ–∂–∏–¥–∞–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
    src = tmp_path / "empty.json"
    dst = tmp_path / "empty.csv"
    src.write_text("[]", encoding="utf-8")

    try:
        json_to_csv(str(src), str(dst))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å –±–µ–∑ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if dst.exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except (ValueError, IndexError):
        pass

def test_csv_to_json_empty(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –ø—É—Å—Ç–æ–≥–æ CSV - –æ–∂–∏–¥–∞–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
    src = tmp_path / "empty.csv"
    dst = tmp_path / "empty.json"
    src.write_text("", encoding="utf-8")

    try:
        csv_to_json(str(src), str(dst))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å –±–µ–∑ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if dst.exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except (ValueError, Exception):
        pass

def test_missing_file(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        csv_to_json("nope.csv", str(tmp_path / "out.json"))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if (tmp_path / "out.json").exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except FileNotFoundError:
        pass
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab07/test_json_csv.png)
### black

![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 3](images/lab07/black.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8

### models.py
```python
from datetime import datetime, date
from dataclasses import dataclass
@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float

    def __post_init__(self):
        #  –í–∞–ª–∏–¥–∞—Ü–∏—è birthdate
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {self.birthdate}. –û–∂–∏–¥–∞–µ—Ç—Å—è YYYY-MM-DD")

        #  –í–∞–ª–∏–¥–∞—Ü–∏—è GPA
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0..5, –ø–æ–ª—É—á–µ–Ω–æ: {self.gpa}")

    # –í–æ–∑—Ä–∞—Å—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞
    def age(self) -> int:
        birth = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        years = today.year - birth.year
        if (today.month, today.day) < (birth.month, birth.day):
            years -= 1
        return years
    # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }


    # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è

    @classmethod
    def from_dict(cls, d: dict):
        return cls(
            fio=d["fio"],
            birthdate=d["birthdate"],
            group=d["group"],
            gpa=d["gpa"]
        )

    def __str__(self):
        return f"{self.fio} ({self.group}), –≤–æ–∑—Ä–∞—Å—Ç: {self.age()}, GPA: {self.gpa}"


```
### serialize.py
```python
import json
from .models import Student
def students_to_json(students, path):
    "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª."
    data = [s.to_dict() for s in students]

    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def students_from_json(path) -> list[Student]:
    "–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞."
    with open(path, "r", encoding="utf-8") as f:
        raw = json.load(f)

    result = []
    for d in raw:
        result.append(Student.from_dict(d))

    return result
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab08/image.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab08/students_output.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 9
### group.py
```python
import csv
from pathlib import Path
from src.lab08.models import Student

class Group:
    def __init__(self, storage_path: str):
        self.path = Path(storage_path)
        self._ensure_storage_exists()

    def _ensure_storage_exists(self):
        "–°–æ–∑–¥–∞—ë—Ç CSV-—Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç."
        if not self.path.exists():
            self.path.parent.mkdir(parents=True, exist_ok=True)
            with self.path.open("w", encoding="utf-8", newline="") as f:
                writer = csv.writer(f)
                writer.writerow(["fio", "birthdate", "group", "gpa"])

    def _read_all(self):
        "–ß–∏—Ç–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ CSV –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π."
        rows = []
        with self.path.open("r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            if reader.fieldnames != ["fio", "birthdate", "group", "gpa"]:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ CSV-—Ñ–∞–π–ª–∞")
            for row in reader:
                if not any(row.values()):
                    continue
                rows.append(row)
        return rows

    def _write_all(self, rows):
        "–ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç CSV –ø–æ–ª–Ω–æ—Å—Ç—å—é."
        with self.path.open("w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["fio", "birthdate", "group", "gpa"])
            writer.writeheader()
            for r in rows:
                writer.writerow(r)
    def list(self):
        "–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ Student."
        rows = self._read_all()
        students = []
        for r in rows:
            r2 = {
                "fio": r["fio"],
                "birthdate": r["birthdate"],
                "group": r["group"],
                "gpa": float(r["gpa"])
            }
            students.append(Student.from_dict(r2))
        return students

    def add(self, student: Student):
        "–î–æ–±–∞–≤–∏—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–∞ –≤ CSV."
        rows = self._read_all()
        row = student.to_dict()
        row["gpa"] = str(row["gpa"])
        rows.append(row)
        self._write_all(rows)

    def find(self, substr: str):
        "–ü–æ–∏—Å–∫ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ –≤ –§–ò–û (–±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)."
        rows = self._read_all()
        substr = substr.lower()
        found = []
        for r in rows:
            if substr in r["fio"].lower():
                r2 = {
                    "fio": r["fio"],
                    "birthdate": r["birthdate"],
                    "group": r["group"],
                    "gpa": float(r["gpa"])
                }
                found.append(Student.from_dict(r2))
        return found

    def remove(self, fio: str):
        "–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å—å –ø–æ —Ç–æ—á–Ω–æ–º—É –§–ò–û. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö."
        rows = self._read_all()
        new_rows = [r for r in rows if r["fio"] != fio]
        removed = len(rows) - len(new_rows)

        if removed:
            self._write_all(new_rows)

        return removed
    def update(self, fio: str, **fields):

        rows = self._read_all()

        for r in rows:
            if r["fio"] == fio:
                r.update({k: str(v) for k, v in fields.items()})

        self._write_all(rows)

```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab09/group.png)
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 2](images/lab09/students_csv.png)
## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 10
### structures.py
```python
from collections import deque


class Stack:
    "–ö–ª–∞—Å—Å —Å—Ç–µ–∫–∞ (LIFO) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ø–∏—Å–∫–∞"

    def __init__(self):
        self._data = []  # –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

    def push(self, item):
        "–î–æ–±–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç –≤ —Å—Ç–µ–∫"
        self._data.append(item)

    def pop(self):
        "–°–Ω—è—Ç—å —ç–ª–µ–º–µ–Ω—Ç —Å –≤–µ—Ä—à–∏–Ω—ã —Å—Ç–µ–∫–∞"
        if self.is_empty():
            raise IndexError("pop from empty stack")
        return self._data.pop()

    def peek(self):
        "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–µ—Ä—Ö–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è"
        if self.is_empty():
            return None
        return self._data[-1]

    def is_empty(self) -> bool:
        "True –µ—Å–ª–∏ —Å—Ç–µ–∫ –ø—É—Å—Ç"
        return len(self._data) == 0

    def __len__(self):
        return len(self._data)

    def __repr__(self):
        return f"Stack({self._data})"


class Queue:
    "–ö–ª–∞—Å—Å –æ—á–µ—Ä–µ–¥–∏ (FIFO) –Ω–∞ –æ—Å–Ω–æ–≤–µ deque"

    def __init__(self):
        self._data = deque()

    def enqueue(self, item):
        "–î–æ–±–∞–≤–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü –æ—á–µ—Ä–µ–¥–∏"
        self._data.append(item)

    def dequeue(self):
        "–£–¥–∞–ª–∏—Ç—å –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –æ—á–µ—Ä–µ–¥–∏"
        if self.is_empty():
            raise IndexError("dequeue from empty queue")
        return self._data.popleft()

    def peek(self):
        "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è"
        if self.is_empty():
            return None
        return self._data[0]

    def is_empty(self) -> bool:
        return len(self._data) == 0

    def __len__(self):
        return len(self._data)

    def __repr__(self):
        return f"Queue({list(self._data)})"
```
### linked_list.py
```python
class Node:
    "–£–∑–µ–ª –æ–¥–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞"

    def __init__(self, value, next=None):
        self.value = value
        self.next = next

    def __repr__(self):
        return f"Node({self.value})"


class SinglyLinkedList:
    "–û–¥–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ø–∏—Å–æ–∫"

    def __init__(self):
        self.head = None
        self._size = 0

    def append(self, value):
        "–í—Å—Ç–∞–≤–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü"
        new_node = Node(value)

        if self.head is None:
            self.head = self.tail = new_node
        else:
            self.tail.next = new_node
            self.tail = new_node

        self._size += 1

    def prepend(self, value):
        "–í—Å—Ç–∞–≤–∏—Ç—å –≤ –Ω–∞—á–∞–ª–æ"
        new_node = Node(value, self.head)
        self.head = new_node
        if self._size == 0:
            self.tail = new_node
        self._size += 1

    def insert(self, idx: int, value):
        "–í—Å—Ç–∞–≤–∫–∞ –ø–æ –∏–Ω–¥–µ–∫—Å—É"
        if idx < 0 or idx > self._size:
            raise IndexError("index out of range")

        if idx == 0:
            self.prepend(value)
            return

        if idx == self._size:
            self.append(value)
            return

        current = self.head
        for _ in range(idx - 1):
            current = current.next

        new_node = Node(value, current.next)
        current.next = new_node
        self._size += 1

    def remove_at(self, idx: int):
        "–£–¥–∞–ª–µ–Ω–∏–µ –ø–æ –∏–Ω–¥–µ–∫—Å—É"
        if idx < 0 or idx >= self._size:
            raise IndexError("index out of range")

        if idx == 0:
            self.head = self.head.next
            if self._size == 1:
                self.tail = None
            self._size -= 1
            return

        current = self.head
        for _ in range(idx - 1):
            current = current.next

        current.next = current.next.next
        if idx == self._size - 1:
            self.tail = current

        self._size -= 1

    def __iter__(self):
        cur = self.head
        while cur:
            yield cur.value
            cur = cur.next

    def __len__(self):
        return self._size

    def __repr__(self):
        return f"SinglyLinkedList({list(self)})"
```
![–ö–∞—Ä—Ç–∏–Ω–∫–∞ 1](images/lab10/image.png)
